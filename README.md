# RAGwithLlamaProject

## Motivation
As most people know, LLMs usually give us hallucination responses, and RAG (Retrieval Augmented Generation) is one of the methods that most people use for tackling hallucination problems. This inspires me to explore how RAG techniques can improve LLMs' responses.

## Resource
- **Full Raw Scopus Dataset:** Resource from 2110531 Data Science and Data Engineering Tools, semester 1/2023, Chulalongkorn University, with the support of the CU Office of Academic Resources (2018 - 2023)
- **Embedding Model:** [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
- **LLM:** Meta's [Llama-2-13b-chat-hf](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf) and its tokenizer
- **Langchain Framework**
- **Vector Database:** [Pinecone](https://www.pinecone.io) 



## Methodology


## Result


## Analysis and further improvement

## Conclusion

## References
- Tutorial: [James Briggs's Better Llama 2 with Retrieval Augmented Generation (RAG)](https://www.youtube.com/watch?v=ypzmPwLH_Q4)
